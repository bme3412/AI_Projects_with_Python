{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cede6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_pipeline import (QueryPipeline as QP, Link, InputComponent)\n",
    "from llama_index.query_engine.pandas import PandasInstructionParser\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397c8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1949860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fd5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./titanic_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f665aab",
   "metadata": {},
   "source": [
    "### Define Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd8b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\")\n",
    "\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(instruction_str=instruction_str,\n",
    "                                                                df_str = df.head())\n",
    "\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "llm = OpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59061ce",
   "metadata": {},
   "source": [
    "### Build Query Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f240a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    }, verbose=True)\n",
    "\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "         Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ])\n",
    "qp.add_link('response_synthesis_prompt','llm2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0e5cf",
   "metadata": {},
   "source": [
    "## Run query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac5c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the oldest surviver?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What is the oldest surviver?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "   survived  pclass  ... cabin embarked\n",
      "0         0       3  ...   NaN  ...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df[df['survived'] == 1]['age'].max()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What is the oldest surviver?\n",
      "pandas_instructions: assistant: df[df['survived'] == 1]['age'].max()\n",
      "pandas_output: 80.0\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: What is the oldest surviver?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df[df['survived'] == 1]['age'].max()\n",
      "\n",
      "Pandas Output: 80.0\n",
      "\n",
      "R...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query_str =\"What is the oldest surviver?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d640b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oldest survivor is 80 years old.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7eb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
